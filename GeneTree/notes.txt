//this files contains some of the ongoing notes.  things in here should be cleared out and made into Issues or just implemented.

take nodes with a large NO CLASS and see if they can be split or reclassed better.  especially bad when all are NO CLASS but still might be good

really need to find a way to go after the small side of the classifier: group 0 has an awful success rate

is it possible to build a second layer of trees for anything that is classed as 0 on the first round?  try to break up the split better

add the missing count to the output summary

use a weighted selector to choose which trees to pick nodes from

create some synthetic data in the program so that is it easier to determine the results of a given run

changes are better suited to go lower in the tree as the generation progresses (much hard to make a good move at the top of tree?)

stop making new trees at some point?  or have a means of letting the randomness in to the next round... then see if these are ever used

add the score and cv score to the output file name

provide a means of doing things with multiple cores

do random trees get better if they are generated with test optimization?

need to capture those data points which are not getting classified and build a tree that works on those

need to use some validation measure to help grow the trees... avoid overfitting when using NO CLASS

review some of the trees created to see how deep/overfit they are

create a "ReplaceNodeWithAnotherNode" to provide a single logic for moving nodes around on a tree
 - needs to handle the case when the node to move is the root

make Random a singelton of some class to avoid passing around so many references.

is it possible to pick different trees from the final population which are different? (save trouble of running tons of times)

logger should write at the end of a population

get the total size of the population in addition to percents

super split and other optimizes should force the categories to the best ones in case classification is used in metric

generate better trees when creating them from scratch (maybe do a a split and optimize each time)

can the load step be optimized with multiple cores?

prevent the case where all nodes go NO CLASS and break things

generate the new trees (if it works) on a Parallel process
 - maybe make fewer of them to get started
 
use the probability (node score) as evidence for the classification it is assigned to
 - allows for target high prob nodes for swapping (regardless of class)
 - allows for splitting low prob nodes to get better movement
 - allows for joining nodes that are all calling the same things the same way (?)

notes for next commit:
 - modified form so that dropping a folder/file copies it to a variable.  this variable is then used for prediction file/folder
 - attempted to do scoring which considers the classificaiton, but it does not appear to offer anything
 - average log loss added to the file name for outputs, could be parsed when predicting if needed
 - using Parallel.For to generate the next generation to get the most out of multiple cores (seems to work)
 - improved (?) the random tree generator to use intelligent splits instead of random tests