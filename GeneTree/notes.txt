//this files contains some of the ongoing notes.  things in here should be cleared out and made into Issues or just implemented.

output an initial status to make it clear that the program is running

take nodes with a large NO CLASS and see if they can be split or reclassed better.  especially bad when all are NO CLASS but still might be good

really need to find a way to go after the small side of the classifier: group 0 has an awful success rate

is it possible to build a second layer of trees for anything that is classed as 0 on the first round?  try to break up the split better

add the missing count to the output summary

use a weighted selector to choose which trees to pick nodes from

create a shorter data file that is faster to load?
 - especially relevant if only taking 50% at a time

create some synthetic data in the program so that is it easier to determine the results of a given run

verify modifications to the score are working correctly with a negative number - or - just change log loss to be positive and minimize the error

do a prediction of the CV error with the out of bag sample

some node divisions only have a single path with traversal, these should be backed up a level to avoid the extra comparison

add the probability value to the tree output at the end

changes are better suited to go lower in the tree as the generation progresses (much hard to make a good move at the top of tree?)

output some graph metrics (max depth, etc.)

is it possible or useful to shoot for a specific score on each generation (i.e. stop at 0.45 loss)?

stop making new trees at some point?  or have a means of letting the randomness in to the next round... then see if these are ever used

add the score and cv score to the output file name

provide a means of doing things with multiple cores

do random trees get better if they are generated with test optimization?

need to capture those data points which are not getting classified and build a tree that works on those

need to use some validation measure to help grow the trees... avoid overfitting when using NO CLASS

remove the LinearComboTreeTest since it does not show up significantly

make the UI pieces dock so that it can be maximized

review some of the trees created to see how deep/overfit they are

create a "ReplaceNodeWithAnotherNode" to provide a single logic for moving nodes around on a tree
 - needs to handle the case when the node to move is the root

apply the penalty for percent classified on a sliding scale of sorts (avoid sharp falloff at limit) = hinged loss type of function

notes for next commit:
 - removed traverseCount from the XML file output, see #62
 - removed the default normalization step that was being done... creates issues for different data loads
 - added a pruning operation in the GeneticOperation class that shortens trees that only have a single subNode being traversed.  It bumps that used node to the parent position and drops the others., see #45
 - attempted to add a hinged loss to the percent classified part of the metric to allow for a soft overshoot